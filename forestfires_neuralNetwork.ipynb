{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forestfires_neuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqLyNrx8nsAojrETlJoEFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarunmer77/assignment-NeuralNetwork/blob/main/forestfires_neuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "JIhnRuHKpaTy",
        "outputId": "f15c3d5f-4fd7-4af0-dbcd-8fdb73aa3e5f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b5307a4-c533-4e21-8961-ee447882951a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8b5307a4-c533-4e21-8961-ee447882951a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving forestfires.csv to forestfires.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDgg3zrdpkQn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy \n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beSJIqIbpuej"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "oRu-6xmbpv40",
        "outputId": "c53e894b-cc99-4e86-f2e7-4fc7126693a9"
      },
      "source": [
        "data = pd.read_csv('forestfires.csv')\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0     mar  fri  86.2   26.2  ...         0         0         0          small\n",
              "1     oct  tue  90.6   35.4  ...         0         1         0          small\n",
              "2     oct  sat  90.6   43.7  ...         0         1         0          small\n",
              "3     mar  fri  91.7   33.3  ...         0         0         0          small\n",
              "4     mar  sun  89.3   51.3  ...         0         0         0          small\n",
              "..    ...  ...   ...    ...  ...       ...       ...       ...            ...\n",
              "512   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "513   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "514   aug  sun  81.6   56.7  ...         0         0         0          large\n",
              "515   aug  sat  94.4  146.0  ...         0         0         0          small\n",
              "516   nov  tue  79.5    3.0  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0VJI1MpzHG",
        "outputId": "d66f3e12-88ee-43d9-dd28-58f048489825"
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month             object\n",
              "day               object\n",
              "FFMC             float64\n",
              "DMC              float64\n",
              "DC               float64\n",
              "ISI              float64\n",
              "temp             float64\n",
              "RH                 int64\n",
              "wind             float64\n",
              "rain             float64\n",
              "area             float64\n",
              "dayfri             int64\n",
              "daymon             int64\n",
              "daysat             int64\n",
              "daysun             int64\n",
              "daythu             int64\n",
              "daytue             int64\n",
              "daywed             int64\n",
              "monthapr           int64\n",
              "monthaug           int64\n",
              "monthdec           int64\n",
              "monthfeb           int64\n",
              "monthjan           int64\n",
              "monthjul           int64\n",
              "monthjun           int64\n",
              "monthmar           int64\n",
              "monthmay           int64\n",
              "monthnov           int64\n",
              "monthoct           int64\n",
              "monthsep           int64\n",
              "size_category     object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFP3-pz0p7e7",
        "outputId": "51d9b89e-a719-41b6-a4c3-5810d998b06f"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "1ObhOWJUp9E5",
        "outputId": "3966a262-bcc2-4dd2-83ef-b69d3ae5e341"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.644681</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>12.847292</td>\n",
              "      <td>0.164410</td>\n",
              "      <td>0.143133</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.117988</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.355899</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.038685</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.332689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.520111</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>63.655818</td>\n",
              "      <td>0.371006</td>\n",
              "      <td>0.350548</td>\n",
              "      <td>0.369244</td>\n",
              "      <td>0.387657</td>\n",
              "      <td>0.322907</td>\n",
              "      <td>0.329662</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.193029</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.241199</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.043980</td>\n",
              "      <td>0.168007</td>\n",
              "      <td>0.471632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.200000</td>\n",
              "      <td>68.600000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>92.900000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.570000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             FFMC         DMC          DC  ...    monthnov    monthoct    monthsep\n",
              "count  517.000000  517.000000  517.000000  ...  517.000000  517.000000  517.000000\n",
              "mean    90.644681  110.872340  547.940039  ...    0.001934    0.029014    0.332689\n",
              "std      5.520111   64.046482  248.066192  ...    0.043980    0.168007    0.471632\n",
              "min     18.700000    1.100000    7.900000  ...    0.000000    0.000000    0.000000\n",
              "25%     90.200000   68.600000  437.700000  ...    0.000000    0.000000    0.000000\n",
              "50%     91.600000  108.300000  664.200000  ...    0.000000    0.000000    0.000000\n",
              "75%     92.900000  142.400000  713.900000  ...    0.000000    0.000000    1.000000\n",
              "max     96.200000  291.300000  860.600000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEN4s3OAp-Qz",
        "outputId": "5b2352aa-d39c-42f0-b46a-72ad8c31e403"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month            0\n",
              "day              0\n",
              "FFMC             0\n",
              "DMC              0\n",
              "DC               0\n",
              "ISI              0\n",
              "temp             0\n",
              "RH               0\n",
              "wind             0\n",
              "rain             0\n",
              "area             0\n",
              "dayfri           0\n",
              "daymon           0\n",
              "daysat           0\n",
              "daysun           0\n",
              "daythu           0\n",
              "daytue           0\n",
              "daywed           0\n",
              "monthapr         0\n",
              "monthaug         0\n",
              "monthdec         0\n",
              "monthfeb         0\n",
              "monthjan         0\n",
              "monthjul         0\n",
              "monthjun         0\n",
              "monthmar         0\n",
              "monthmay         0\n",
              "monthnov         0\n",
              "monthoct         0\n",
              "monthsep         0\n",
              "size_category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRbXSk9PqBB3",
        "outputId": "71d771a9-fef1-4dd2-ae74-9a6ad155b04a"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
              "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
              "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
              "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
              "       'monthoct', 'monthsep', 'size_category'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aj-grxTqE_F"
      },
      "source": [
        "data.drop(['month','day'],axis=1,inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Sp0KZAJqqIya",
        "outputId": "f7ce5a80-2136-4683-db45-d2bc33b2e68e"
      },
      "source": [
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows Ã— 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     FFMC    DMC     DC   ISI  ...  monthnov  monthoct  monthsep  size_category\n",
              "0    86.2   26.2   94.3   5.1  ...         0         0         0          small\n",
              "1    90.6   35.4  669.1   6.7  ...         0         1         0          small\n",
              "2    90.6   43.7  686.9   6.7  ...         0         1         0          small\n",
              "3    91.7   33.3   77.5   9.0  ...         0         0         0          small\n",
              "4    89.3   51.3  102.2   9.6  ...         0         0         0          small\n",
              "..    ...    ...    ...   ...  ...       ...       ...       ...            ...\n",
              "512  81.6   56.7  665.6   1.9  ...         0         0         0          large\n",
              "513  81.6   56.7  665.6   1.9  ...         0         0         0          large\n",
              "514  81.6   56.7  665.6   1.9  ...         0         0         0          large\n",
              "515  94.4  146.0  614.7  11.3  ...         0         0         0          small\n",
              "516  79.5    3.0  106.7   1.1  ...         1         0         0          small\n",
              "\n",
              "[517 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOrnzLERqJ8N"
      },
      "source": [
        "le = LabelEncoder()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF0hnbxRqNbc"
      },
      "source": [
        "data['size_category'] = le.fit_transform(data['size_category'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2vkTs3IqRjE"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KW9qVkFqbxr"
      },
      "source": [
        "# Model Building"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbS_PMf7qdtk"
      },
      "source": [
        "x = data.drop('size_category',axis=1)\n",
        "y = data['size_category']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "piLYu7RYqsuP",
        "outputId": "6a0065a2-b60c-45c7-b9ef-a86e8d15d201"
      },
      "source": [
        "x"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     FFMC    DMC     DC   ISI  ...  monthmay  monthnov  monthoct  monthsep\n",
              "0    86.2   26.2   94.3   5.1  ...         0         0         0         0\n",
              "1    90.6   35.4  669.1   6.7  ...         0         0         1         0\n",
              "2    90.6   43.7  686.9   6.7  ...         0         0         1         0\n",
              "3    91.7   33.3   77.5   9.0  ...         0         0         0         0\n",
              "4    89.3   51.3  102.2   9.6  ...         0         0         0         0\n",
              "..    ...    ...    ...   ...  ...       ...       ...       ...       ...\n",
              "512  81.6   56.7  665.6   1.9  ...         0         0         0         0\n",
              "513  81.6   56.7  665.6   1.9  ...         0         0         0         0\n",
              "514  81.6   56.7  665.6   1.9  ...         0         0         0         0\n",
              "515  94.4  146.0  614.7  11.3  ...         0         0         0         0\n",
              "516  79.5    3.0  106.7   1.1  ...         0         1         0         0\n",
              "\n",
              "[517 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6qvSvRzqtmS",
        "outputId": "4aef31da-1c2d-458b-e83d-ef4eae8188ba"
      },
      "source": [
        "y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "512    0\n",
              "513    0\n",
              "514    0\n",
              "515    1\n",
              "516    1\n",
              "Name: size_category, Length: 517, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHCjXuKBquMP"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ2Qr-b_qwYM"
      },
      "source": [
        "# Standardization"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzru5re9qx9F",
        "outputId": "4726d5a1-a1aa-49a7-9587-b50e1f827a10"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "x_scaled"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
              "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
              "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
              "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
              "       ...,\n",
              "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
              "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
              "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
              "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzhKiYT6qzwH"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pkIL7UUq5_B"
      },
      "source": [
        "# Splitting data into test and train"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB09z1Muq9TK",
        "outputId": "d50a5cbb-65a1-4333-9ca9-42c4c795e8ce"
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.20,random_state=15,stratify = y)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((413, 28), (104, 28), (413,), (104,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpsDgOVOq9q9"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(28,input_dim=28,activation='relu'))\n",
        "model.add(Dense(24,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8aPIyTXrAbM"
      },
      "source": [
        "# Compiling the model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdApE8_2rEcw"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcssARm6rE0N"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxxDRFNorGDF"
      },
      "source": [
        "# Model Training"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4leMvGerHHE",
        "outputId": "01779a4a-6ee1-4859-db64-1125616b9695"
      },
      "source": [
        "model.fit(X_train,y_train,validation_split=0.33,epochs=150,batch_size=10)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "28/28 [==============================] - 1s 11ms/step - loss: 0.6408 - accuracy: 0.7210 - val_loss: 0.6473 - val_accuracy: 0.7445\n",
            "Epoch 2/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.7246 - val_loss: 0.6328 - val_accuracy: 0.7445\n",
            "Epoch 3/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.7246 - val_loss: 0.6238 - val_accuracy: 0.7445\n",
            "Epoch 4/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7283 - val_loss: 0.6175 - val_accuracy: 0.7445\n",
            "Epoch 5/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7283 - val_loss: 0.6159 - val_accuracy: 0.7445\n",
            "Epoch 6/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7319 - val_loss: 0.6162 - val_accuracy: 0.7591\n",
            "Epoch 7/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7391 - val_loss: 0.6171 - val_accuracy: 0.7664\n",
            "Epoch 8/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7609 - val_loss: 0.6188 - val_accuracy: 0.7810\n",
            "Epoch 9/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7681 - val_loss: 0.6266 - val_accuracy: 0.7883\n",
            "Epoch 10/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7935 - val_loss: 0.6352 - val_accuracy: 0.7956\n",
            "Epoch 11/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7899 - val_loss: 0.6424 - val_accuracy: 0.7956\n",
            "Epoch 12/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8007 - val_loss: 0.6492 - val_accuracy: 0.7956\n",
            "Epoch 13/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.8116 - val_loss: 0.6600 - val_accuracy: 0.7956\n",
            "Epoch 14/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4027 - accuracy: 0.8188 - val_loss: 0.6694 - val_accuracy: 0.7883\n",
            "Epoch 15/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3891 - accuracy: 0.8152 - val_loss: 0.6825 - val_accuracy: 0.7883\n",
            "Epoch 16/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8333 - val_loss: 0.6914 - val_accuracy: 0.7883\n",
            "Epoch 17/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8406 - val_loss: 0.7035 - val_accuracy: 0.7883\n",
            "Epoch 18/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8587 - val_loss: 0.7072 - val_accuracy: 0.7883\n",
            "Epoch 19/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8587 - val_loss: 0.7232 - val_accuracy: 0.7956\n",
            "Epoch 20/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8768 - val_loss: 0.7339 - val_accuracy: 0.8175\n",
            "Epoch 21/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8768 - val_loss: 0.7454 - val_accuracy: 0.8029\n",
            "Epoch 22/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8841 - val_loss: 0.7579 - val_accuracy: 0.8248\n",
            "Epoch 23/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2697 - accuracy: 0.8986 - val_loss: 0.7757 - val_accuracy: 0.8175\n",
            "Epoch 24/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.8913 - val_loss: 0.7913 - val_accuracy: 0.8102\n",
            "Epoch 25/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2402 - accuracy: 0.9022 - val_loss: 0.7964 - val_accuracy: 0.8321\n",
            "Epoch 26/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9203 - val_loss: 0.8298 - val_accuracy: 0.8321\n",
            "Epoch 27/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9094 - val_loss: 0.8449 - val_accuracy: 0.8321\n",
            "Epoch 28/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9275 - val_loss: 0.8560 - val_accuracy: 0.8321\n",
            "Epoch 29/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1943 - accuracy: 0.9312 - val_loss: 0.8712 - val_accuracy: 0.8321\n",
            "Epoch 30/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9384 - val_loss: 0.8866 - val_accuracy: 0.8321\n",
            "Epoch 31/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1719 - accuracy: 0.9420 - val_loss: 0.8979 - val_accuracy: 0.8321\n",
            "Epoch 32/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9493 - val_loss: 0.9315 - val_accuracy: 0.8321\n",
            "Epoch 33/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9565 - val_loss: 0.9363 - val_accuracy: 0.8321\n",
            "Epoch 34/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9529 - val_loss: 0.9546 - val_accuracy: 0.8248\n",
            "Epoch 35/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9638 - val_loss: 0.9834 - val_accuracy: 0.8321\n",
            "Epoch 36/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9601 - val_loss: 0.9786 - val_accuracy: 0.8321\n",
            "Epoch 37/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1281 - accuracy: 0.9565 - val_loss: 0.9970 - val_accuracy: 0.8248\n",
            "Epoch 38/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9710 - val_loss: 1.0108 - val_accuracy: 0.8248\n",
            "Epoch 39/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9710 - val_loss: 1.0357 - val_accuracy: 0.8248\n",
            "Epoch 40/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1066 - accuracy: 0.9674 - val_loss: 1.0411 - val_accuracy: 0.8248\n",
            "Epoch 41/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9746 - val_loss: 1.0656 - val_accuracy: 0.8248\n",
            "Epoch 42/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9746 - val_loss: 1.0641 - val_accuracy: 0.8248\n",
            "Epoch 43/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9746 - val_loss: 1.0930 - val_accuracy: 0.8248\n",
            "Epoch 44/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0882 - accuracy: 0.9783 - val_loss: 1.1000 - val_accuracy: 0.8467\n",
            "Epoch 45/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9710 - val_loss: 1.1091 - val_accuracy: 0.8394\n",
            "Epoch 46/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9783 - val_loss: 1.1229 - val_accuracy: 0.8321\n",
            "Epoch 47/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9891 - val_loss: 1.1517 - val_accuracy: 0.8321\n",
            "Epoch 48/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 1.1450 - val_accuracy: 0.8394\n",
            "Epoch 49/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9891 - val_loss: 1.1646 - val_accuracy: 0.8321\n",
            "Epoch 50/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9928 - val_loss: 1.1777 - val_accuracy: 0.8394\n",
            "Epoch 51/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9928 - val_loss: 1.1960 - val_accuracy: 0.8467\n",
            "Epoch 52/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9928 - val_loss: 1.2038 - val_accuracy: 0.8394\n",
            "Epoch 53/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9891 - val_loss: 1.2274 - val_accuracy: 0.8394\n",
            "Epoch 54/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 1.2236 - val_accuracy: 0.8467\n",
            "Epoch 55/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9891 - val_loss: 1.2346 - val_accuracy: 0.8394\n",
            "Epoch 56/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 1.2497 - val_accuracy: 0.8394\n",
            "Epoch 57/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9928 - val_loss: 1.2715 - val_accuracy: 0.8394\n",
            "Epoch 58/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9928 - val_loss: 1.2925 - val_accuracy: 0.8394\n",
            "Epoch 59/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9964 - val_loss: 1.3009 - val_accuracy: 0.8394\n",
            "Epoch 60/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.3093 - val_accuracy: 0.8467\n",
            "Epoch 61/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.8394\n",
            "Epoch 62/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 1.3316 - val_accuracy: 0.8467\n",
            "Epoch 63/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9928 - val_loss: 1.3477 - val_accuracy: 0.8467\n",
            "Epoch 64/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.3628 - val_accuracy: 0.8394\n",
            "Epoch 65/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 1.3791 - val_accuracy: 0.8467\n",
            "Epoch 66/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0367 - accuracy: 0.9964 - val_loss: 1.3852 - val_accuracy: 0.8467\n",
            "Epoch 67/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 0.9964 - val_loss: 1.3922 - val_accuracy: 0.8467\n",
            "Epoch 68/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9964 - val_loss: 1.4025 - val_accuracy: 0.8467\n",
            "Epoch 69/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.4236 - val_accuracy: 0.8467\n",
            "Epoch 70/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.4283 - val_accuracy: 0.8467\n",
            "Epoch 71/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9964 - val_loss: 1.4476 - val_accuracy: 0.8467\n",
            "Epoch 72/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0293 - accuracy: 0.9964 - val_loss: 1.4534 - val_accuracy: 0.8467\n",
            "Epoch 73/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 1.4672 - val_accuracy: 0.8467\n",
            "Epoch 74/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.4708 - val_accuracy: 0.8467\n",
            "Epoch 75/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4953 - val_accuracy: 0.8467\n",
            "Epoch 76/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9964 - val_loss: 1.4878 - val_accuracy: 0.8467\n",
            "Epoch 77/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.5189 - val_accuracy: 0.8467\n",
            "Epoch 78/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 1.5158 - val_accuracy: 0.8467\n",
            "Epoch 79/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9964 - val_loss: 1.5273 - val_accuracy: 0.8467\n",
            "Epoch 80/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.5238 - val_accuracy: 0.8467\n",
            "Epoch 81/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9964 - val_loss: 1.5604 - val_accuracy: 0.8467\n",
            "Epoch 82/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.5571 - val_accuracy: 0.8467\n",
            "Epoch 83/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.5575 - val_accuracy: 0.8467\n",
            "Epoch 84/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.5709 - val_accuracy: 0.8467\n",
            "Epoch 85/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9964 - val_loss: 1.5937 - val_accuracy: 0.8467\n",
            "Epoch 86/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.5933 - val_accuracy: 0.8467\n",
            "Epoch 87/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 1.6077 - val_accuracy: 0.8467\n",
            "Epoch 88/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.6239 - val_accuracy: 0.8467\n",
            "Epoch 89/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.6251 - val_accuracy: 0.8467\n",
            "Epoch 90/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.6439 - val_accuracy: 0.8467\n",
            "Epoch 91/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.6437 - val_accuracy: 0.8467\n",
            "Epoch 92/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.6524 - val_accuracy: 0.8467\n",
            "Epoch 93/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.6712 - val_accuracy: 0.8467\n",
            "Epoch 94/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 1.6732 - val_accuracy: 0.8467\n",
            "Epoch 95/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9964 - val_loss: 1.6958 - val_accuracy: 0.8467\n",
            "Epoch 96/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.7056 - val_accuracy: 0.8467\n",
            "Epoch 97/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.7126 - val_accuracy: 0.8467\n",
            "Epoch 98/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.8467\n",
            "Epoch 99/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.7285 - val_accuracy: 0.8467\n",
            "Epoch 100/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.7429 - val_accuracy: 0.8467\n",
            "Epoch 101/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.8467\n",
            "Epoch 102/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.7526 - val_accuracy: 0.8467\n",
            "Epoch 103/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.7659 - val_accuracy: 0.8540\n",
            "Epoch 104/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.7691 - val_accuracy: 0.8467\n",
            "Epoch 105/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.7892 - val_accuracy: 0.8467\n",
            "Epoch 106/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.7907 - val_accuracy: 0.8540\n",
            "Epoch 107/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.8117 - val_accuracy: 0.8467\n",
            "Epoch 108/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.8129 - val_accuracy: 0.8540\n",
            "Epoch 109/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8210 - val_accuracy: 0.8540\n",
            "Epoch 110/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.8311 - val_accuracy: 0.8540\n",
            "Epoch 111/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.8415 - val_accuracy: 0.8540\n",
            "Epoch 112/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.8376 - val_accuracy: 0.8540\n",
            "Epoch 113/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.8475 - val_accuracy: 0.8540\n",
            "Epoch 114/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.8835 - val_accuracy: 0.8540\n",
            "Epoch 115/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.8626 - val_accuracy: 0.8613\n",
            "Epoch 116/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.8948 - val_accuracy: 0.8540\n",
            "Epoch 117/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.8613\n",
            "Epoch 118/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.8982 - val_accuracy: 0.8540\n",
            "Epoch 119/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.9036 - val_accuracy: 0.8540\n",
            "Epoch 120/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.9250 - val_accuracy: 0.8540\n",
            "Epoch 121/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.8540\n",
            "Epoch 122/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.9435 - val_accuracy: 0.8540\n",
            "Epoch 123/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.9486 - val_accuracy: 0.8540\n",
            "Epoch 124/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.9589 - val_accuracy: 0.8540\n",
            "Epoch 125/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.9749 - val_accuracy: 0.8540\n",
            "Epoch 126/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.9870 - val_accuracy: 0.8540\n",
            "Epoch 127/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.9922 - val_accuracy: 0.8540\n",
            "Epoch 128/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.0008 - val_accuracy: 0.8540\n",
            "Epoch 129/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.0129 - val_accuracy: 0.8540\n",
            "Epoch 130/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.0150 - val_accuracy: 0.8540\n",
            "Epoch 131/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.0329 - val_accuracy: 0.8540\n",
            "Epoch 132/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0368 - val_accuracy: 0.8540\n",
            "Epoch 133/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.0513 - val_accuracy: 0.8540\n",
            "Epoch 134/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0618 - val_accuracy: 0.8540\n",
            "Epoch 135/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0684 - val_accuracy: 0.8613\n",
            "Epoch 136/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.0773 - val_accuracy: 0.8540\n",
            "Epoch 137/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.0780 - val_accuracy: 0.8613\n",
            "Epoch 138/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.0934 - val_accuracy: 0.8613\n",
            "Epoch 139/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.1054 - val_accuracy: 0.8613\n",
            "Epoch 140/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1161 - val_accuracy: 0.8613\n",
            "Epoch 141/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1242 - val_accuracy: 0.8613\n",
            "Epoch 142/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1393 - val_accuracy: 0.8613\n",
            "Epoch 143/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1457 - val_accuracy: 0.8613\n",
            "Epoch 144/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.1513 - val_accuracy: 0.8613\n",
            "Epoch 145/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1625 - val_accuracy: 0.8613\n",
            "Epoch 146/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.1734 - val_accuracy: 0.8613\n",
            "Epoch 147/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.1836 - val_accuracy: 0.8686\n",
            "Epoch 148/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2020 - val_accuracy: 0.8613\n",
            "Epoch 149/150\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.2031 - val_accuracy: 0.8613\n",
            "Epoch 150/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2138 - val_accuracy: 0.8613\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b3a57cb90>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgX8D4TFrJLA"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_YJIGfKrQal"
      },
      "source": [
        "# Model Testing"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRpQSgW2rRlc"
      },
      "source": [
        "y_pred_train = model.predict(X_train)\n",
        "rounded = [round(x[0]) for x in y_pred_train]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5UhXe2frTWb"
      },
      "source": [
        "y_pred_train1 = pd.DataFrame(rounded)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "nwoZa9zArU-H",
        "outputId": "001ed697-f03c-4f56-af54-a569e44e0424"
      },
      "source": [
        "y_pred_train1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "..  ..\n",
              "408  1\n",
              "409  1\n",
              "410  0\n",
              "411  1\n",
              "412  1\n",
              "\n",
              "[413 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Q3sXK6rWF7"
      },
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "rounded1    = [round(x[0]) for x in y_pred_test]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "f6HD72NQrX17",
        "outputId": "b0e47d25-d984-4233-d4d0-6ca1a15f4188"
      },
      "source": [
        "y_pred_test1 = pd.DataFrame(rounded1)\n",
        "y_pred_test1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "0    0\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "..  ..\n",
              "99   0\n",
              "100  1\n",
              "101  1\n",
              "102  1\n",
              "103  0\n",
              "\n",
              "[104 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgXLr83srZI3"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgskDmyirajY"
      },
      "source": [
        "# Model Evaluation\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cDUcBpQrcHt",
        "outputId": "0c1f8471-e344-4e65-8fcc-4857f323c2d3"
      },
      "source": [
        "Accuracy_Train = model.evaluate(X_train,y_pred_train1,verbose=0)\n",
        "Accuracy_Train"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.010790713131427765, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHYW8yMlrdrB",
        "outputId": "d58ce2bd-eab3-4345-b328-6ce421e196f3"
      },
      "source": [
        "Accuracy_Test = model.evaluate(X_test,y_pred_test1,verbose=0)\n",
        "Accuracy_Test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02205720543861389, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0KtOT8crfHk"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTrxLlHrhPn"
      },
      "source": [
        "# Visualizing Accuracy and Loss"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwjaZVAOrjnq",
        "outputId": "d6190f44-313f-4a40-a4d0-8ca37252f31d"
      },
      "source": [
        "History = model.fit(X_test,y_pred_test1,validation_split=0.33,epochs=150,batch_size=10)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 2/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
            "Epoch 3/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
            "Epoch 4/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 5/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 6/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 7/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
            "Epoch 8/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 9.6837e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 9/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.9087e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 10/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 8.3415e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 11/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 8.0470e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 12/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 7.7125e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 13/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 7.3946e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
            "Epoch 14/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 7.0865e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 15/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 6.9290e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
            "Epoch 16/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 6.7031e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 17/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 6.4885e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 18/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.2752e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 19/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 6.1417e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 20/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.9613e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 21/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.7871e-04 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 22/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.6501e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 23/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.5394e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 24/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.3900e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
            "Epoch 25/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.2826e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
            "Epoch 26/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.1447e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 27/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.0309e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
            "Epoch 28/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4.9603e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 29/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4.8433e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 30/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4.7425e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.6591e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 32/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.5675e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 33/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.4812e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.4031e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.3196e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.2391e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.1712e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4.1044e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 4.0347e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.9611e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8968e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.8502e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.7955e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 3.7334e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.6679e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.6294e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 3.5574e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.5112e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.4768e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.4260e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.3754e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.3321e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.2846e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.2429e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.2122e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.1517e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.1298e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.0820e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 3.0441e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.0015e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.9902e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.9364e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.9052e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.8682e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.8374e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8062e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.7683e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.7404e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.7114e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.6813e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.6545e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.6275e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.6003e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.5650e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.5553e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.5130e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.4902e-04 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.4683e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.4390e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.4150e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.3963e-04 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.3661e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.3486e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.3215e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2997e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.2770e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.2586e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.2374e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.2163e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1988e-04 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1788e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1579e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.1356e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.1158e-04 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.0981e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.0813e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.0612e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.0465e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.0243e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 2.0088e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.9915e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.9780e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.9617e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.9436e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.9273e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.9110e-04 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.8980e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.8812e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8677e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.8542e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.8402e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.8205e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.8076e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.7951e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.7797e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.7649e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.7501e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.7386e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.7274e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.7145e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.7035e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.6876e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.6772e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6644e-04 - accuracy: 1.0000 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.6491e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.6393e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6263e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.6178e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.6058e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.5929e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.5804e-04 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.5682e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.5594e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.5472e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.5366e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.5249e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.5155e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.5075e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4962e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.4857e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4761e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4661e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.4578e-04 - accuracy: 1.0000 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4455e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4359e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 1.4272e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 1.4178e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.4074e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.4001e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 1.3896e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB6dVkvErkKf"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoJvgTUrpQq",
        "outputId": "f380ca42-54e0-4914-b377-eb2f3ed7b3f3"
      },
      "source": [
        "model.history.history.keys()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxC4KDA4rrq4"
      },
      "source": [
        ""
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "M5SWi4ierulA",
        "outputId": "81880d74-a72f-4e8d-eafc-939f23f16192"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(History.history['accuracy'])\n",
        "plt.plot(History.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(History.history['loss'])\n",
        "plt.plot(History.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-cCNEJIru_o"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL2Yae9SrwIX"
      },
      "source": [
        "# Tuning Of Hyperparameters : Batch Size and epochs"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH-UnwNVr0Ya"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8KLFSZbr2B9"
      },
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model1 = Sequential()\n",
        "    model1.add(Dense(30, input_dim=28, activation='relu'))\n",
        "    model1.add(Dense(28, activation='relu'))\n",
        "    model1.add(Dense(1,activation='sigmoid'))\n",
        "    \n",
        "   \n",
        "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model1"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCdCcaGssMvT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go4l0cixr4IQ",
        "outputId": "cb2c4d01-f2c8-4a56-e80b-b24a5c52828c"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model2 = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model2,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(x_scaled,y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.962 total time=   1.4s\n",
            "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.750 total time=   1.6s\n",
            "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.563 total time=   2.0s\n",
            "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.689 total time=   1.4s\n",
            "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.728 total time=   1.4s\n",
            "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.971 total time=   4.0s\n",
            "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.788 total time=   3.9s\n",
            "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.825 total time=   5.8s\n",
            "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.825 total time=   3.8s\n",
            "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.835 total time=   3.7s\n",
            "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=0.971 total time=   6.8s\n",
            "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.846 total time=  11.0s\n",
            "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.845 total time=   7.3s\n",
            "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.864 total time=  10.9s\n",
            "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.864 total time=  11.0s\n",
            "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.990 total time=   1.4s\n",
            "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.740 total time=   1.4s\n",
            "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.631 total time=   1.0s\n",
            "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.718 total time=   1.3s\n",
            "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.971 total time=   3.3s\n",
            "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.769 total time=   2.4s\n",
            "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.816 total time=   2.3s\n",
            "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.825 total time=   2.8s\n",
            "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.825 total time=   3.3s\n",
            "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=0.981 total time=   5.8s\n",
            "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.808 total time=   3.9s\n",
            "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.835 total time=   3.9s\n",
            "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.845 total time=   3.9s\n",
            "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.854 total time=   5.8s\n",
            "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   0.9s\n",
            "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.750 total time=   0.9s\n",
            "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.524 total time=   1.0s\n",
            "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7b30eebe60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.689 total time=   0.9s\n",
            "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f7b3a436710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.709 total time=   1.3s\n",
            "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.913 total time=   2.0s\n",
            "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.760 total time=   1.6s\n",
            "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.670 total time=   2.0s\n",
            "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.718 total time=   2.0s\n",
            "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.825 total time=   1.6s\n",
            "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.981 total time=   3.3s\n",
            "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.808 total time=   3.3s\n",
            "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.816 total time=   2.5s\n",
            "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.806 total time=   2.6s\n",
            "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.825 total time=   3.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxQREiZRsUf9",
        "outputId": "c374923a-b355-4e81-b26b-39fb86368038"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.8780246615409851, using {'batch_size': 10, 'epochs': 100}\n",
            "0.7384241819381714,0.1289703799982274 with: {'batch_size': 10, 'epochs': 10}\n",
            "0.849010455608368,0.06310728335591141 with: {'batch_size': 10, 'epochs': 50}\n",
            "0.8780246615409851,0.0473096543996193 with: {'batch_size': 10, 'epochs': 100}\n",
            "0.7519790887832641,0.1248620216743414 with: {'batch_size': 20, 'epochs': 10}\n",
            "0.8412808060646058,0.06816972173248197 with: {'batch_size': 20, 'epochs': 50}\n",
            "0.864488422870636,0.06019139105809694 with: {'batch_size': 20, 'epochs': 100}\n",
            "0.734466016292572,0.15338269587518782 with: {'batch_size': 40, 'epochs': 10}\n",
            "0.7773338317871094,0.08502831168630647 with: {'batch_size': 40, 'epochs': 50}\n",
            "0.8470126867294312,0.06722819311112345 with: {'batch_size': 40, 'epochs': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPsOLIvysZrY"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhyavFTwsa7C"
      },
      "source": [
        "# Tuning of Hyperparameter : Number of Neurons in activation layer"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDrReCPasjA3"
      },
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model1(neuron1,neuron2):\n",
        "    model3 = Sequential()\n",
        "    model3.add(Dense(neuron1,input_dim = 28,activation = 'relu'))\n",
        "    model3.add(Dense(neuron2,activation = 'relu'))\n",
        "    model3.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    model3.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "    return model3"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB-PYHgIslKv",
        "outputId": "51658b7c-b9a1-4280-b5ce-bc3b593fc971"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model4 = KerasClassifier(build_fn = create_model1,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "neuron1 = [24,28,35]\n",
        "neuron2 = [20,24,28]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid2        = GridSearchCV(estimator = model4,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result2 = grid2.fit(x_scaled,y)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START neuron1=24, neuron2=20......................................\n",
            "[CV 1/5; 1/9] END .......neuron1=24, neuron2=20;, score=0.962 total time=   1.0s\n",
            "[CV 2/5; 1/9] START neuron1=24, neuron2=20......................................\n",
            "[CV 2/5; 1/9] END .......neuron1=24, neuron2=20;, score=0.750 total time=   0.9s\n",
            "[CV 3/5; 1/9] START neuron1=24, neuron2=20......................................\n",
            "[CV 3/5; 1/9] END .......neuron1=24, neuron2=20;, score=0.534 total time=   1.1s\n",
            "[CV 4/5; 1/9] START neuron1=24, neuron2=20......................................\n",
            "[CV 4/5; 1/9] END .......neuron1=24, neuron2=20;, score=0.689 total time=   0.9s\n",
            "[CV 5/5; 1/9] START neuron1=24, neuron2=20......................................\n",
            "[CV 5/5; 1/9] END .......neuron1=24, neuron2=20;, score=0.699 total time=   0.9s\n",
            "[CV 1/5; 2/9] START neuron1=24, neuron2=24......................................\n",
            "[CV 1/5; 2/9] END .......neuron1=24, neuron2=24;, score=0.952 total time=   0.9s\n",
            "[CV 2/5; 2/9] START neuron1=24, neuron2=24......................................\n",
            "[CV 2/5; 2/9] END .......neuron1=24, neuron2=24;, score=0.760 total time=   1.0s\n",
            "[CV 3/5; 2/9] START neuron1=24, neuron2=24......................................\n",
            "[CV 3/5; 2/9] END .......neuron1=24, neuron2=24;, score=0.534 total time=   0.9s\n",
            "[CV 4/5; 2/9] START neuron1=24, neuron2=24......................................\n",
            "[CV 4/5; 2/9] END .......neuron1=24, neuron2=24;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 2/9] START neuron1=24, neuron2=24......................................\n",
            "[CV 5/5; 2/9] END .......neuron1=24, neuron2=24;, score=0.670 total time=   1.2s\n",
            "[CV 1/5; 3/9] START neuron1=24, neuron2=28......................................\n",
            "[CV 1/5; 3/9] END .......neuron1=24, neuron2=28;, score=0.990 total time=   0.9s\n",
            "[CV 2/5; 3/9] START neuron1=24, neuron2=28......................................\n",
            "[CV 2/5; 3/9] END .......neuron1=24, neuron2=28;, score=0.750 total time=   0.9s\n",
            "[CV 3/5; 3/9] START neuron1=24, neuron2=28......................................\n",
            "[CV 3/5; 3/9] END .......neuron1=24, neuron2=28;, score=0.553 total time=   1.0s\n",
            "[CV 4/5; 3/9] START neuron1=24, neuron2=28......................................\n",
            "[CV 4/5; 3/9] END .......neuron1=24, neuron2=28;, score=0.680 total time=   0.9s\n",
            "[CV 5/5; 3/9] START neuron1=24, neuron2=28......................................\n",
            "[CV 5/5; 3/9] END .......neuron1=24, neuron2=28;, score=0.709 total time=   1.0s\n",
            "[CV 1/5; 4/9] START neuron1=28, neuron2=20......................................\n",
            "[CV 1/5; 4/9] END .......neuron1=28, neuron2=20;, score=0.990 total time=   1.0s\n",
            "[CV 2/5; 4/9] START neuron1=28, neuron2=20......................................\n",
            "[CV 2/5; 4/9] END .......neuron1=28, neuron2=20;, score=0.750 total time=   0.9s\n",
            "[CV 3/5; 4/9] START neuron1=28, neuron2=20......................................\n",
            "[CV 3/5; 4/9] END .......neuron1=28, neuron2=20;, score=0.524 total time=   0.9s\n",
            "[CV 4/5; 4/9] START neuron1=28, neuron2=20......................................\n",
            "[CV 4/5; 4/9] END .......neuron1=28, neuron2=20;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 4/9] START neuron1=28, neuron2=20......................................\n",
            "[CV 5/5; 4/9] END .......neuron1=28, neuron2=20;, score=0.718 total time=   0.9s\n",
            "[CV 1/5; 5/9] START neuron1=28, neuron2=24......................................\n",
            "[CV 1/5; 5/9] END .......neuron1=28, neuron2=24;, score=0.990 total time=   1.4s\n",
            "[CV 2/5; 5/9] START neuron1=28, neuron2=24......................................\n",
            "[CV 2/5; 5/9] END .......neuron1=28, neuron2=24;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 5/9] START neuron1=28, neuron2=24......................................\n",
            "[CV 3/5; 5/9] END .......neuron1=28, neuron2=24;, score=0.515 total time=   1.0s\n",
            "[CV 4/5; 5/9] START neuron1=28, neuron2=24......................................\n",
            "[CV 4/5; 5/9] END .......neuron1=28, neuron2=24;, score=0.689 total time=   1.0s\n",
            "[CV 5/5; 5/9] START neuron1=28, neuron2=24......................................\n",
            "[CV 5/5; 5/9] END .......neuron1=28, neuron2=24;, score=0.709 total time=   1.0s\n",
            "[CV 1/5; 6/9] START neuron1=28, neuron2=28......................................\n",
            "[CV 1/5; 6/9] END .......neuron1=28, neuron2=28;, score=1.000 total time=   0.9s\n",
            "[CV 2/5; 6/9] START neuron1=28, neuron2=28......................................\n",
            "[CV 2/5; 6/9] END .......neuron1=28, neuron2=28;, score=0.750 total time=   0.9s\n",
            "[CV 3/5; 6/9] START neuron1=28, neuron2=28......................................\n",
            "[CV 3/5; 6/9] END .......neuron1=28, neuron2=28;, score=0.553 total time=   1.0s\n",
            "[CV 4/5; 6/9] START neuron1=28, neuron2=28......................................\n",
            "[CV 4/5; 6/9] END .......neuron1=28, neuron2=28;, score=0.689 total time=   0.9s\n",
            "[CV 5/5; 6/9] START neuron1=28, neuron2=28......................................\n",
            "[CV 5/5; 6/9] END .......neuron1=28, neuron2=28;, score=0.718 total time=   1.0s\n",
            "[CV 1/5; 7/9] START neuron1=35, neuron2=20......................................\n",
            "[CV 1/5; 7/9] END .......neuron1=35, neuron2=20;, score=0.990 total time=   0.9s\n",
            "[CV 2/5; 7/9] START neuron1=35, neuron2=20......................................\n",
            "[CV 2/5; 7/9] END .......neuron1=35, neuron2=20;, score=0.750 total time=   1.4s\n",
            "[CV 3/5; 7/9] START neuron1=35, neuron2=20......................................\n",
            "[CV 3/5; 7/9] END .......neuron1=35, neuron2=20;, score=0.573 total time=   1.0s\n",
            "[CV 4/5; 7/9] START neuron1=35, neuron2=20......................................\n",
            "[CV 4/5; 7/9] END .......neuron1=35, neuron2=20;, score=0.689 total time=   0.9s\n",
            "[CV 5/5; 7/9] START neuron1=35, neuron2=20......................................\n",
            "[CV 5/5; 7/9] END .......neuron1=35, neuron2=20;, score=0.718 total time=   1.0s\n",
            "[CV 1/5; 8/9] START neuron1=35, neuron2=24......................................\n",
            "[CV 1/5; 8/9] END .......neuron1=35, neuron2=24;, score=0.990 total time=   0.9s\n",
            "[CV 2/5; 8/9] START neuron1=35, neuron2=24......................................\n",
            "[CV 2/5; 8/9] END .......neuron1=35, neuron2=24;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 8/9] START neuron1=35, neuron2=24......................................\n",
            "[CV 3/5; 8/9] END .......neuron1=35, neuron2=24;, score=0.544 total time=   1.0s\n",
            "[CV 4/5; 8/9] START neuron1=35, neuron2=24......................................\n",
            "[CV 4/5; 8/9] END .......neuron1=35, neuron2=24;, score=0.689 total time=   0.9s\n",
            "[CV 5/5; 8/9] START neuron1=35, neuron2=24......................................\n",
            "[CV 5/5; 8/9] END .......neuron1=35, neuron2=24;, score=0.699 total time=   0.9s\n",
            "[CV 1/5; 9/9] START neuron1=35, neuron2=28......................................\n",
            "[CV 1/5; 9/9] END .......neuron1=35, neuron2=28;, score=0.962 total time=   1.0s\n",
            "[CV 2/5; 9/9] START neuron1=35, neuron2=28......................................\n",
            "[CV 2/5; 9/9] END .......neuron1=35, neuron2=28;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 9/9] START neuron1=35, neuron2=28......................................\n",
            "[CV 3/5; 9/9] END .......neuron1=35, neuron2=28;, score=0.621 total time=   1.3s\n",
            "[CV 4/5; 9/9] START neuron1=35, neuron2=28......................................\n",
            "[CV 4/5; 9/9] END .......neuron1=35, neuron2=28;, score=0.680 total time=   0.9s\n",
            "[CV 5/5; 9/9] START neuron1=35, neuron2=28......................................\n",
            "[CV 5/5; 9/9] END .......neuron1=35, neuron2=28;, score=0.709 total time=   1.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-B7l71snLr",
        "outputId": "b1c5d2e7-653d-46a0-e7e6-af4a43cd7011"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result2.best_score_,grid_result2.best_params_))\n",
        "means = grid_result2.cv_results_['mean_test_score']\n",
        "stds = grid_result2.cv_results_['std_test_score']\n",
        "params = grid_result2.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.744249427318573, using {'neuron1': 35, 'neuron2': 28}\n",
            "0.726773715019226,0.13783731616669082 with: {'neuron1': 24, 'neuron2': 20}\n",
            "0.7190067172050476,0.13718375110904218 with: {'neuron1': 24, 'neuron2': 24}\n",
            "0.7364264369010926,0.14294962235195152 with: {'neuron1': 24, 'neuron2': 28}\n",
            "0.7325429439544677,0.15044226118005988 with: {'neuron1': 28, 'neuron2': 20}\n",
            "0.7306011915206909,0.15278633950214154 with: {'neuron1': 28, 'neuron2': 24}\n",
            "0.7422330141067505,0.1452778850024509 with: {'neuron1': 28, 'neuron2': 28}\n",
            "0.744193434715271,0.1368854696410139 with: {'neuron1': 35, 'neuron2': 20}\n",
            "0.7344846963882447,0.1452069523806895 with: {'neuron1': 35, 'neuron2': 24}\n",
            "0.744249427318573,0.11643770880999836 with: {'neuron1': 35, 'neuron2': 28}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKOs3tnowl1d"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oO0RT-cwnll"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl9OERdDwo0x"
      },
      "source": [
        "# Tuning Hyperparameter : Activation Function"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp0Xc7XUwsh5"
      },
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model2(activation_function):\n",
        "    model4 = Sequential()\n",
        "    model4.add(Dense(28,input_dim = 28,activation = activation_function))\n",
        "    model4.add(Dense(24,activation = activation_function))\n",
        "    model4.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    model4.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "    return model4"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYnlcvx0wt_o",
        "outputId": "8265c068-8ecb-4220-a267-418ef32325c4"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model5 = KerasClassifier(build_fn = create_model2,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "activation_function = ['softmax','relu','tanh']\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(activation_function=activation_function)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid3        = GridSearchCV(estimator = model5,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result3 = grid3.fit(x_scaled,y)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV 1/5; 1/3] START activation_function=softmax.................................\n",
            "[CV 1/5; 1/3] END ..activation_function=softmax;, score=1.000 total time=   1.1s\n",
            "[CV 2/5; 1/3] START activation_function=softmax.................................\n",
            "[CV 2/5; 1/3] END ..activation_function=softmax;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 1/3] START activation_function=softmax.................................\n",
            "[CV 3/5; 1/3] END ..activation_function=softmax;, score=0.524 total time=   0.9s\n",
            "[CV 4/5; 1/3] START activation_function=softmax.................................\n",
            "[CV 4/5; 1/3] END ..activation_function=softmax;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 1/3] START activation_function=softmax.................................\n",
            "[CV 5/5; 1/3] END ..activation_function=softmax;, score=0.699 total time=   1.0s\n",
            "[CV 1/5; 2/3] START activation_function=relu....................................\n",
            "[CV 1/5; 2/3] END .....activation_function=relu;, score=0.981 total time=   0.9s\n",
            "[CV 2/5; 2/3] START activation_function=relu....................................\n",
            "[CV 2/5; 2/3] END .....activation_function=relu;, score=0.750 total time=   1.0s\n",
            "[CV 3/5; 2/3] START activation_function=relu....................................\n",
            "[CV 3/5; 2/3] END .....activation_function=relu;, score=0.515 total time=   1.3s\n",
            "[CV 4/5; 2/3] START activation_function=relu....................................\n",
            "[CV 4/5; 2/3] END .....activation_function=relu;, score=0.680 total time=   1.0s\n",
            "[CV 5/5; 2/3] START activation_function=relu....................................\n",
            "[CV 5/5; 2/3] END .....activation_function=relu;, score=0.709 total time=   1.0s\n",
            "[CV 1/5; 3/3] START activation_function=tanh....................................\n",
            "[CV 1/5; 3/3] END .....activation_function=tanh;, score=1.000 total time=   1.0s\n",
            "[CV 2/5; 3/3] START activation_function=tanh....................................\n",
            "[CV 2/5; 3/3] END .....activation_function=tanh;, score=0.740 total time=   0.9s\n",
            "[CV 3/5; 3/3] START activation_function=tanh....................................\n",
            "[CV 3/5; 3/3] END .....activation_function=tanh;, score=0.592 total time=   0.9s\n",
            "[CV 4/5; 3/3] START activation_function=tanh....................................\n",
            "[CV 4/5; 3/3] END .....activation_function=tanh;, score=0.670 total time=   1.0s\n",
            "[CV 5/5; 3/3] START activation_function=tanh....................................\n",
            "[CV 5/5; 3/3] END .....activation_function=tanh;, score=0.728 total time=   0.9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZzgI6gJwv0s",
        "outputId": "ea396d15-c3a0-4b0c-e63e-ab326a7884f5"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result3.best_score_,grid_result3.best_params_))\n",
        "means = grid_result3.cv_results_['mean_test_score']\n",
        "stds = grid_result3.cv_results_['std_test_score']\n",
        "params = grid_result3.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.7461351752281189, using {'activation_function': 'tanh'}\n",
            "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax'}\n",
            "0.7267363548278809,0.15009068975270679 with: {'activation_function': 'relu'}\n",
            "0.7461351752281189,0.13733239151926718 with: {'activation_function': 'tanh'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0azmA17w8Sc"
      },
      "source": [
        "# best result is when the Activation function is 'tanh'"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxfUoUMWxADD"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVPh964w1dB_"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTuKhFvoxAkl"
      },
      "source": [
        ""
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2S7A1q3yIeO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}